#include <opencv2/imgcodecs.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
#include <cstdio>
#include <iostream>
#include <stdexcept>
#include <string>
#include "api/client.h"
#include "api/response.h"
#include "api/environment.h"
#include "processors/track.h"
#include "processors/track-collector.h"
#include "processors/object-stream.h"

using namespace cv;

//Motion detection parameters
const int           MIN_AREA = 10000;
const int           KERNEL_SIZE = 7;
const int           dilation_size = 5;
const int           resize_to_height = 480;
const double        SIGMA = 4.5;

//API parameters
const std::string   CAMERA_NAME = "VirtualCam_1";

//
const int           FLIPBOOK_FPS = 1;
const Size          FLIPBOOK_SIZE = Size(480,360);
const int           FLIPBOOK_MAX_DUR_S = 60;
const char*         FLIPBOOK_TMP_FILE = "flip.mp4";
const int           BACKGROUND_UPDATE_MIN = 1;
const char*         BACKGROUND_TMP_FILE = "back.jpg";
const char*         BLOB_TMP_FILE = "blob.jpg";

prism::connect::api::Client client{prism::connect::api::environment::ApiRoot(),
	                                       prism::connect::api::environment::ApiToken()};
std::unique_ptr<prism::connect::api::Instrument> this_camera;
std::unique_ptr<VideoWriter> writer;
std::unique_ptr<prism::connect::processors::Track>  track;

Rect resizeRect(Rect r,float scale)
{
    return Rect(r.x*scale,r.y*scale,r.width*scale,r.height*scale);
}

void initPrismService()
{
	auto accounts = client.QueryAccounts();

	std::cout<<"API Endpoint"<<prism::connect::api::environment::ApiRoot()<<std::endl;
	for (const auto& account : accounts) {
	        std::cout << "Account[" << account.id_ << "]:" << std::endl;
	        std::cout << "Name: " << account.name_ << std::endl;
	        std::cout << "Url: " << account.url_ << std::endl;
	        std::cout << "Instruments Url: " << account.instruments_url_ << std::endl;
	        std::cout << std::endl;

	        // Get the list of Instruments belonging to an Account
	        std::vector<prism::connect::api::Instrument> instruments = client.QueryInstruments(account);

	        //Find our camera by name
	        bool found = false;
	        for(auto& instrument : instruments)
	        {
	        	if(instrument.name_ == CAMERA_NAME)
	        	{
	        		found = true;
	        		this_camera.reset(new prism::connect::api::Instrument(instrument));
	        	}
	        }

	        //If camera does not exist - create it
	        if(!found)
	        {
	        	this_camera.reset(new prism::connect::api::Instrument());
	        	this_camera->name_ = CAMERA_NAME;
	        	this_camera->instrument_type_ = "camera";

	        	// Register an unregistered Instrument to an Account
	        	prism::connect::api::Response result = client.RegisterInstrument(account, *this_camera.get());
	        	std::cerr<<" Camera registration status"<<result.status_code<<" {"<<result.text<<"}"<<std::endl;
	        }
	        std::cout << "Instrument[" << this_camera->name_ << "]:" << std::endl;

	        break;
	}
}


int main(int, char**)
{
    std::string cmd, stream_id, stream_URL, FormatCode;
    std::vector<int> compression_params;
    compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
    compression_params.push_back(95);
    
    VideoCapture cap("Burglar.mp4");
    if(!cap.isOpened()) // check if we succeeded
        return -1;
    int fps = cap.get(CV_CAP_PROP_FPS);
    
    std::cout << "Processing..." << std::endl;
    

    //Init connect service
    initPrismService();

    // create Background Subtractor objects
    
    Mat fgMaskMOG2; // fg mask fg mask generated by MOG2 method
    Ptr<BackgroundSubtractor> pMOG2; // MOG2 Background subtractor
    pMOG2 = createBackgroundSubtractorMOG2(); // MOG2 approach
    
    Mat firstFrame;
    int fnum = 0;
    std::chrono::system_clock::time_point ftime;
    int last_fnum = -10000;
    int saved_frames = 0;
    bool motion = false;
    bool was_motion = false;
    int  last_b_update = -10000;
    std::chrono::system_clock::time_point motion_start;
    int blob_id = 0;
    
    //Set current timepoint to 1h ago since we processing faster than real time
    //and will be posting to future
    ftime = std::chrono::system_clock::now() - std::chrono::hours(1);
    for(;;)
    {
        Mat frame, gray_frame;

        cap >> frame; // get a new frame from camera
        if (frame.empty())
            {
                // reach to the end of the video file
                break;
            }
        //get frame timestamp
        ftime += std::chrono::milliseconds(1000 / fps);
        
        cvtColor(frame, gray_frame, COLOR_BGR2GRAY); //switch to grayscale
        
        float scale =(float) resize_to_height/gray_frame.rows;
        int resized_width = gray_frame.cols*scale;
        resize(gray_frame, gray_frame, Size(resized_width,resize_to_height), 0, 0, CV_INTER_CUBIC); // resize
        
        GaussianBlur(gray_frame, gray_frame, Size(KERNEL_SIZE,KERNEL_SIZE), SIGMA, SIGMA);
        pMOG2->apply(gray_frame, fgMaskMOG2);
        
        Mat dilated;
        Mat element = getStructuringElement( MORPH_ELLIPSE,
                                            Size( 2*dilation_size + 1, 2*dilation_size+1 ),
                                            Point( dilation_size, dilation_size ) );
        dilate(fgMaskMOG2,dilated,element); // dilate the thresholded image to fill in holes, then find contours on thresholded image
        
        std::vector<std::vector<Point> > contours;
        std::vector<Vec4i> hierarchy;
        findContours( dilated, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point(0, 0) ); //find contours
        
        motion = false;
        for( int i = 0; i< contours.size(); i++ ) // loop over the contours
        {
            double area = contourArea(contours[i]);
            if(area < MIN_AREA)
                continue;
            
            motion = true;
            CvRect r = boundingRect(contours[i]);
            r = resizeRect(r,1.0/scale);

            //Mark motion on frame
            Scalar color = Scalar(255, 0,0 );
            rectangle( frame, r,color);

            //Add motion blob to object stream
            Mat blob = Mat(frame, r);
            imwrite(BLOB_TMP_FILE,blob,compression_params);
            prism::connect::processors::ObjectStream object_s(blob_id,ftime,r.x,r.y,r.width,r.height,frame.cols,frame.rows);
            std::cerr<<"Posting object stream"<<std::endl;
            prism::connect::api::Response result = client.PostImageFileObjectStream(*this_camera.get(),object_s.ToJson(),BLOB_TMP_FILE);
            std::cerr<<" status"<<result.status_code<<" {"<<result.text<<"}"<<std::endl;
            blob_id++;
        }
        
        //Update flipbook
        if(motion)
        {
        	if(!was_motion)
        	{
        		//Remove old file
        		std::remove(FLIPBOOK_TMP_FILE);
        		//Open video file
        		std::cout<<"Open file:"<<FLIPBOOK_TMP_FILE<<std::endl;
        		writer.reset(new VideoWriter(FLIPBOOK_TMP_FILE,VideoWriter::fourcc('H','2','6','4'),FLIPBOOK_FPS,FLIPBOOK_SIZE,1));
        		saved_frames = 0;

        	}

        	if (fnum - last_fnum > fps/FLIPBOOK_FPS)
			{
        		Mat flip_frame;
        		resize(frame, flip_frame, FLIPBOOK_SIZE, 0, 0, CV_INTER_CUBIC);
        		writer->write(flip_frame);
        		saved_frames++;
        		last_fnum = fnum;
			}

        }else if(was_motion)
        {
        	prism::connect::api::Response result;
        	//finalize stream, upload data
        	std::cout<<"Close file:"<<FLIPBOOK_TMP_FILE<<std::endl;
        	writer->release();
        	last_fnum =-1;
        	std::cerr<<"Posting flipbook file "<<FLIPBOOK_TMP_FILE<<std::endl;
        	result = client.PostVideoFileFlipbook(*this_camera.get(),ftime - std::chrono::milliseconds((1000*saved_frames) / FLIPBOOK_FPS) ,ftime,FLIPBOOK_SIZE.width,FLIPBOOK_SIZE.height,saved_frames,FLIPBOOK_TMP_FILE);
        	std::cerr<<" status"<<result.status_code<<" {"<<result.text<<"}"<<std::endl;
        }


        //update background every BACKGROUND_UPDATE_MIN minutes
        if( (fnum-last_b_update)/(float)(fps*60)> BACKGROUND_UPDATE_MIN)
        {
        	Mat background;
        	pMOG2->getBackgroundImage(background);
        	imwrite(BACKGROUND_TMP_FILE, background, compression_params); // save image
            std::cerr<<"Posting background file "<<BACKGROUND_TMP_FILE<<std::endl;
            prism::connect::api::Response result = client.PostImageFile(*this_camera.get(),"BACKGROUND",ftime,ftime,BACKGROUND_TMP_FILE);
            std::cerr<<" status"<<result.status_code<<" {"<<result.text<<"}"<<std::endl;
            last_b_update = fnum;
        }
        fnum++;
        was_motion = motion;
    }
    
    // the camera will be deinitialized automatically in VideoCapture destructor
    return 0;
}
